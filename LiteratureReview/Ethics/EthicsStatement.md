# Ethical Considerations for MSc Research Project

**Project Title:**  
*Adversarial Attacks on AI-Based Biometric Authentication Systems: Detection and Defence in Practice*

## Ethical Scope and Relevance

This project investigates how adversarial attacks affect AI-based facial recognition systems and explores lightweight defence strategies suitable for small-to-medium-sized enterprises (SMEs). Although the project does **not involve human participants**, it must still meet ethical standards concerning data usage, transparency, reproducibility, and responsible AI development.

As defined by the University of Essex Online (2025), research ethics ensures that projects are accountable, legally compliant, and technically sound. Ethical approval is still necessary even when working with pre-existing data to assess potential data security or misuse risks.

## Key Ethical Considerations

### 1. Data Handling and Consent

The project uses publicly available datasets such as **Labeled Faces in the Wild (LFW)** and **CelebA**, which are licensed for research use. No personal data will be collected. Since participants did not provide informed consent directly to the researcher, it is essential to verify the datasets’ terms of use and ensure usage aligns with academic guidelines (Huang et al., 2007; Liu et al., 2015).

### 2. Confidentiality and Anonymity

While no new human data is collected, images used in facial recognition research inherently contain identity cues. All results will be presented in aggregate form, with no focus on individual identity or subject re-identification (Abdullahi, 2024). Dataset integrity and anonymity are maintained by adhering strictly to the datasets' publication policies.

### 3. Use of AI and Adversarial Attacks

The project will simulate attacks on face recognition models (e.g., FGSM, PGD). This type of research carries a dual-use risk—it could, if misused, inform malicious actors. To mitigate this, the project includes strong documentation, disclaimers, and defensive countermeasures. The final outputs will focus on reproducibility for defensive use only (Goodfellow et al., 2015; Kilany & Mahfouz, 2025).

### 4. Storage and Security

All datasets and code will be stored securely on a password-protected, encrypted local drive, with backups on encrypted cloud storage. No data will be uploaded that violates dataset licences. The codebase will be hosted on GitHub, but images will not be redistributed.

## Conclusion

While this project does not involve new human participants, ethical approval remains necessary to ensure appropriate use of AI, synthetic image data, and reproducible security frameworks. As advised by UoEO’s ethical approval policy (University of Essex Online, 2025), risk is minimised by relying only on licensed, open-access datasets and producing outputs that support transparency, defensive tooling, and SME-focused reproducibility.

## References

Abdullahi, S.M., 2024. Biometric template attacks and recent protection mechanisms. *Patterns*, 5(4), p.100500.  
Goodfellow, I.J., Shlens, J. and Szegedy, C., 2015. Explaining and harnessing adversarial examples. *arXiv preprint*, arXiv:1412.6572.  
Kilany, S. and Mahfouz, A., 2025. A survey of deep face verification attacks and defences. *Scientific Reports*, 15(1), p.30861.  
Liu, Z., Luo, P., Wang, X. and Tang, X., 2015. Deep learning face attributes in the wild. *Proceedings of the IEEE International Conference on Computer Vision (ICCV)*, pp.3730–3738.  
University of Essex Online, 2025. *Research: Ethical Approval Policy*. [PDF available on Moodle].
