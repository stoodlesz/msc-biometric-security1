# üìÖ Dev Log ‚Äî 16 September 2025

**Goal:** Finalise dataset setup, train baseline model, and prepare Jupyter notebook structure for main dissertation project.

---

## ‚úÖ Achievements

### 1. Dataset Setup
- Created `Datasets/` directory with structured subfolders for:
  - `lfw-dataset/lfw-deepfunneled`
  - `celeba-dataset/`
- Updated `download_datasets.sh` to:
  - Use working Kaggle download commands
  - Unzip directly into usable folders
- Updated `README.md` with clear instructions for dataset setup and Kaggle API usage.

### 2. Jupyter Notebook Structure Finalised
Created 3 separate notebooks to logically split the project:
- `1_data_loading_preprocessing.ipynb`  
  ‚Äì Loads and preprocesses datasets (LFW and CelebA), applies `transforms`, inspects class distribution.
  
- `2_model_training_fgsm_attack.ipynb`  
  ‚Äì Loads pretrained ResNet18, modifies classifier for LFW classes, trains on a subset, then runs FGSM attack and logs results.
  
- `3_defence_and_evaluation.ipynb`  
  ‚Äì Placeholder setup for testing defences (e.g., JPEG compression, detection methods) and evaluating accuracy, latency, ASR, etc.
  
- `4_combining_into_one_notebook_1-3.ipynb` 
  ‚Äì Me combining the ideas into one file, into a cell for each. This is the last work I will do on my own trained model.

### 3. Version Control Fixes
- Resolved broken pushes by:
  - Removing unnecessary large files (e.g., model checkpoints)
  - Clearing output from notebooks with `nbconvert`
  - Updating `.gitignore` to exclude datasets and `.pt` files

---

## üß† Lessons & Considerations

- Adversarial training and model evaluation require good classification accuracy ‚Äî current losses are high; further training or simplified class subset may be needed.
- LFW has 5,749 classes ‚Äî training with full set is infeasible on CPU. Consider reducing dataset to top N classes.
- Using pretrained ResNet with transfer learning is more aligned with SME scenarios than building from scratch.
- Keeping notebooks small and modular improves clarity and reproducibility.

---

## üìù Next Steps

- Improve training loop and optionally freeze lower ResNet layers
- Begin implementing JPEG preprocessing defence
- Write evaluation functions for FAR, FRR, ASR, and latency
- Begin drafting dissertation Methodology section
