# Project Log â€“ 8 October 2025  
**Baseline Model, FGSM Adversarial Attack & JPEG Defence Implementation**

## Summary

Today focused on validating an adversarial pipeline using a **pretrained FaceNet model** applied to the **LFW dataset**. This setup simulates the kind of biometric authentication system an SME might rely on. 

I have developed a baseline adversarial test flow with three stages:
1. **Correct classification** of an image using the pretrained model.
2. **FGSM attack** applied to generate a minimally perturbed adversarial image.
3. **JPEG compression defence** to recover performance after the attack.

## What the Baseline Code Does

- Loads LFW dataset and passes a face image through a **pretrained FaceNet** model.
- Measures cosine similarity between the **original image's embedding** and:
  - The **FGSM-attacked image**
  - The **JPEG-compressed recovery of the adversarial image**
- If the clean image is not correctly classified, the attack and defence steps are skipped.

Cosine similarity values indicate how "alike" the model sees the images.  
**Higher = more similar**, and **lower = successful attack**.

---

## Example Result

âœ… Correct Prediction Found: George_W_Bush
âš ï¸ Adversarial Prediction: Colin_Powell
ðŸŽ¯ Cosine similarity (original vs adv): 0.41
ðŸ”§ Cosine similarity (original vs JPEG-defended): 0.82


This shows:
- The FGSM attack was successful.
- JPEG compression partially recovered the original identity in the modelâ€™s embedding space.

---

## Why This Matters for SMEs

- Training your own model is **time-consuming** and **resource-intensive**. I've seen losses stay >8 even after 20 batches when training from scratch.
- **Pretrained models** offer a head start, but they are still vulnerable to attack.
- Lightweight defences like **JPEG compression** are accessible and donâ€™t require deep ML knowledge, making them ideal for **SME deployment**.

---

## What Should Happen

1. Clean image â†’ correctly classified
2. FGSM perturbed image â†’ misclassified
3. JPEG defence â†’ classification improves OR cosine similarity increases

This flow shows how vulnerable models are in production and helps SMEs assess trade-offs between robustness and implementation complexity.

---

## Issues / Challenges

- Sometimes no correctly classified image is found in batch â†’ pipeline is skipped.
- Cosine similarity and predictions need further benchmarking for different Îµ values.
- Need to improve result tracking + evaluation outputs for each defence.

---

## Next

- Improve batch selection and metrics tracking.
- Test other lightweight defences (e.g. Gaussian blur, cropping).
- Finalise baseline notebook and begin literature review writing.

